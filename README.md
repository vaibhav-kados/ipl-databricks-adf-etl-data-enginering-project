# ğŸ IPL Data Analysis Project â€“ Azure Data Factory & Databricks (Medallion Architecture)

This project demonstrates an **end-to-end Data Engineering pipeline** using **Azure Data Factory (ADF)**, **Azure Databricks**, and **Azure Data Lake Storage Gen2 (ADLS Gen2)**.  
It is based on the **Medallion Architecture (Bronze â†’ Silver â†’ Gold)** and processes **IPL cricket data (matches & deliveries)** to build analytical insights.

---

## ğŸš€ Project Architecture

The project follows the Medallion architecture with three layers:

1. **Bronze Layer** â€“ Stores raw data from the source system in Delta format.  
2. **Silver Layer** â€“ Performs cleaning, transformations, and incremental loads.  
3. **Gold Layer** â€“ Stores aggregated and business-ready data (e.g., Batsman performance summary).

ğŸ“Œ **Architecture Diagram**  
![Architecture Diagram](architecture/ipl_de_architecture.png)  

---

## ğŸ”„ Data Flow

1. **ADF Master Pipeline**  
   - Triggers automatically when new data lands in the **bronze container** in ADLS Gen2.  
   - Uses **Get Metadata** and **If Condition** activity to check whether **both files (`matches` & `deliveries`)** are present.  
   - If yes â†’ Extracts the file names and passes them as **parameters** to a Databricks job.  

   ğŸ“Œ **Screenshot:** ADF Master Pipeline  
   _Attach here_: `images/1.adf_master_pipeline.png`

2. **Databricks Job Workflow**
   - **Step 1: Create External Location**  
     Configures access to ADLS Gen2.  
     ğŸ“Œ Screenshot: `images/databricks_external_location.png`

   - **Step 2: Create Catalog & Schemas**  
     Creates:
     - Catalog: `ipl_data_analysis_catalog`  
     - Schemas: `bronze`, `silver`, `gold`  
     ğŸ“Œ Screenshot: `images/databricks_catalog_schema.png`

   - **Step 3: Create Bronze Tables**  
     Raw files (`matches`, `deliveries`) are stored as **Delta tables** in the bronze layer.  
     Metadata columns added: `data_source`, `ingestion_date`  
     ğŸ“Œ Screenshot: `images/databricks_bronze_tables.png`

   - **Step 4: Create Silver Tables**  
     - Incremental load applied  
       - `matches` â†’ Incremental on `match_id`  
       - `deliveries` â†’ Incremental on (`match_id`, `inning`, `over`, `ball`)  
     - Null handling, cleaning & schema enforcement performed.  
     ğŸ“Œ Screenshot: `images/databricks_silver_tables.png`

   - **Step 5: Create Gold Tables**  
     - Analytical tables prepared (example: **Batsman Performance Summary**)  
       - Total runs  
       - Balls faced  
       - Strike rate & other metrics  
     ğŸ“Œ Screenshot: `images/databricks_gold_tables.png`

---

## ğŸ—‚ Project Structure

ipl-databricks-adf-etl-data-enginering-project/
â”‚
â”œâ”€â”€ notebooks/ # Databricks notebooks (ETL code)
â”œâ”€â”€ pipelines/ # ADF pipeline JSON exports
â”œâ”€â”€ images/ # Screenshots (architecture, pipeline, notebooks, dashboards)
â”œâ”€â”€ README.md # Project documentation

---

## âš™ï¸ Technologies Used

- **Azure Data Factory (ADF)** â€“ Orchestration & pipeline automation  
- **Azure Databricks** â€“ Data processing & transformation  
- **ADLS Gen2** â€“ Storage for raw & processed data  
- **Delta Lake** â€“ For incremental loads & ACID transactions  
- **PySpark / SQL** â€“ Transformations & aggregations  

---

## ğŸ“Š Final Output (Gold Layer)

Example: **Batsman Performance Summary Table**  
- `batsman_name`  
- `total_runs`  
- `balls_faced`  
- `strike_rate`  
- `4s` / `6s` count  
- `matches_played`  

ğŸ“Œ Screenshot: Gold Table Preview  
_Attach here_: `images/batsman_summary.png`

---

## ğŸ“· Screenshots to Attach

1. `images/architecture.png` â€“ Overall Architecture  
2. `images/adf_master_pipeline.png` â€“ ADF Master Pipeline  
3. `images/databricks_external_location.png` â€“ External Location Setup  
4. `images/databricks_catalog_schema.png` â€“ Catalog & Schema Creation  
5. `images/databricks_bronze_tables.png` â€“ Bronze Tables in Databricks  
6. `images/databricks_silver_tables.png` â€“ Silver Tables in Databricks  
7. `images/databricks_gold_tables.png` â€“ Gold Tables in Databricks  
8. `images/batsman_summary.png` â€“ Gold Table Example (Batsman Performance)

---

## ğŸ“Œ How to Run This Project

1. Upload raw `matches.csv` and `deliveries.csv` files to **bronze container** in ADLS Gen2.  
2. ADF Master Pipeline triggers automatically â†’ validates files â†’ invokes Databricks job.  
3. Databricks notebooks process data into **Bronze â†’ Silver â†’ Gold** layers.  
4. Query Gold tables for analytics using **Databricks SQL** / **Power BI**.

---

## ğŸ† Key Learnings

- Implemented **Medallion Architecture** in Azure.  
- Built **incremental pipelines** using Delta Lake.  
- Automated **data ingestion â†’ transformation â†’ analytics** workflow with ADF + Databricks.  
- Designed reusable & scalable architecture for future datasets.  

---

## ğŸ‘¨â€ğŸ’» Author

**Vaibhav Kados**  
- Azure Data Engineer | Data Enthusiast  
- [LinkedIn](https://www.linkedin.com) | [GitHub](https://github.com)
